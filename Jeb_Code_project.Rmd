---
title: "Jeb_code_work"
output: html_document
date: "2024-03-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown











#Using code for cleaning data


```{r}
library(readr)
library(dplyr)
library(tidyr)
library(tidyverse)
#setwd("C:/Users/maxb1/OneDrive/Documents/UNC_Stuff/stor_565/final_project")
data = bigcitiesall
total = data %>% filter(geo_label_citystate == "U.S. Total")
```




```{r}
#Clean data code (data defined as latest_filtered)
#Taking out na values and only using 2021
cities = bigcities_wide
us_total = cities %>% filter(geo_label_city == "U.S. Total")
## Work with 2021 
new_cities = cities %>% filter(date_label == 2021)
na_count = colSums(is.na(new_cities)) / nrow(new_cities)
lowna = na_count[colSums(is.na(new_cities)) / nrow(new_cities) < .33]
lowna_cols = names(lowna)
cities_nona = new_cities %>% select(all_of(lowna_cols))
non_zero_sd_columns <- apply(cities, 2, sd) != 0

#Jeb for you
df <- cities_nona %>%
  mutate(across(where(is.numeric), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))
df
latest_filtered = df
```
```{r}
# Find columns with non-constant variance
non_constant_columns <- apply(latest_filtered[2:ncol(latest_filtered)], 2, function(x) var(x) != 0)

# Keep only columns with non-constant variance
latest_filtered_clean <- latest_filtered[, c(TRUE, non_constant_columns)]

# Perform PCA on cleaned dataset
pca_health <- prcomp(latest_filtered_clean[2:ncol(latest_filtered_clean)], scale = TRUE)
# Print summary of PCA results
summary(pca_health)
```


```{r}
pca_health$rotation
pca
```


```{r}
# Extract PC scores
PC1 <- pca_health$x[, 1]
PC2 <- pca_health$x[, 2]

# Plot PC1 vs PC2
plot(PC1, PC2, xlab = "Principal Component 1", ylab = "Principal Component 2", main = "PC1 vs PC2")


data.frame(cor(pca_health$x))
```


```{r}
#Redefining latest data into latest_data_num
set.seed(123)

latest_data_num = latest_filtered_clean[2:ncol(latest_filtered_clean)]

#preforming tsne

library(Rtsne)

# Assuming 'data' is your data matrix or data frame

perplexity <- 10  # You can adjust this value as needed

# Run t-SNE with specified parameters
tsne_result <- Rtsne(latest_data_num, perplexity = perplexity)

# Coordinates of the embedded data points
embedded_data <- tsne_result$Y

# Plot the embedded data points
plot(embedded_data, col = 'blue', pch = 20)

```



```{r}
# Assuming 'latest_data_num' is your prepared data matrix or data frame

# Perform k-means clustering with k clusters
k <- 3  # Specify the number of clusters
kmeans_result <- kmeans(latest_data_num, centers = k)

# Extract cluster assignments
cluster_assignments <- kmeans_result$cluster

# Print cluster centers
print(kmeans_result$centers)

# Print cluster sizes
table(cluster_assignments)

 

```


```{r}

# Assuming 'latest_data_num' is your prepared data matrix or data frame

# Perform k-means clustering with k clusters
k <- 4  # Specify the number of clusters
kmeans_result <- kmeans(latest_data_num, centers = k)

# Extract cluster assignments
cluster_assignments <- kmeans_result$cluster

# Print cluster centers
print(kmeans_result$centers)

# Print cluster sizes
table(cluster_assignments)

 

```

#K-means on PCA and original Data needed

#Kmeans function on the Original Data (k=2:17)
```{r}
performKMeansRange <- function(data_frame, k_range, distance_method = "euclidean") {
  # Ensure data frame doesn't contain NA, NaN, or Inf values
  # Remove rows containing any such values
  clean_data_frame <- na.omit(data_frame) # More efficient way to remove rows with NA, NaN or Inf
  
  # Initialize an empty data frame to store results
  results_df <- data.frame(k = integer(), cluster = integer(), size = integer(), 
                           withinss = numeric(), tot.withinss = numeric(), betweenss = numeric(), 
                           totss = numeric(), stringsAsFactors = FALSE)

  # Iterate over the range of k values
  for (k in k_range) {
    # Perform k-means clustering with the current k
    set.seed(123) # Ensure reproducibility
    kmeans_result <- kmeans(clean_data_frame, centers = k, iter.max = 1000, nstart = 25)
    
    # Calculate between-cluster sum of squares
    betweenss <- kmeans_result$totss - kmeans_result$tot.withinss
    
    # Construct a temporary data frame to hold cluster sizes and statistics for this k
    cluster_sizes <- table(kmeans_result$cluster)
    temp_df <- data.frame(k = rep(k, length(cluster_sizes)), 
                          cluster = 1:length(cluster_sizes), 
                          size = as.vector(cluster_sizes), 
                          withinss = kmeans_result$withinss, 
                          tot.withinss = rep(kmeans_result$tot.withinss, length(cluster_sizes)),
                          betweenss = rep(betweenss, length(cluster_sizes)),
                          totss = rep(kmeans_result$totss, length(cluster_sizes)), 
                          stringsAsFactors = FALSE)
    
    # Combine the temporary data frame with the overall results data frame
    results_df <- rbind(results_df, temp_df)
  }
  
  return(results_df)
}

k_range = 2:17

results_df <- performKMeansRange(latest_data_num, k_range)

# View the results
print(results_df)

```


#Now lets preform k_means on the scaled data to avoid distribution related errors
```{r}

performKMeansRange(scale(latest_data_num), k_range)


```







#K_means on PCA components

```{r}

#Note pca_health is 
k_range = 2:17
performKMeansRange(pca_health$x, k_range)


```








